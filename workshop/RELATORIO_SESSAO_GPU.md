# RELAT√ìRIO COMPLETO - SESS√ÉO DE TREINAMENTO GPU

**Data:** 2025-11-08  
**GPU:** g5.2xlarge (NVIDIA A10G, 24GB VRAM)  
**Objetivo:** Treinar modelo DL e validar pipeline completo

---

## 1. PROVISIONAMENTO AWS

### ‚úÖ Tentativa 1: g5.2xlarge com Ubuntu AMI (FALHOU)
- **Spot:** MaxSpotInstanceCountExceeded
- **On-demand:** Provisionado (i-04240f90f7e32f969, IP: 52.71.94.184)
- **Problema:** NVIDIA drivers n√£o carregaram ap√≥s cloud-init
- **Solu√ß√£o:** Terminado, tentativa 2

### ‚úÖ Tentativa 2: g5.2xlarge com Deep Learning AMI (SUCESSO)
- **Inst√¢ncia:** i-0c98ea0f63170edc3
- **IP:** 54.172.227.79
- **AMI:** ami-06d97595b5bdd43b2 (Amazon Linux 2, Deep Learning)
- **GPU:** NVIDIA A10G, 23GB VRAM, Driver 570.195.03, CUDA 12.8
- **Status:** ‚úÖ nvidia-smi funcionou imediatamente
- **Custo:** ~$0.50/hora on-demand

---

## 2. CONFIGURA√á√ÉO DO AMBIENTE

### Software instalado:
```bash
Python: 3.10 (n√£o default 3.7)
PyTorch: 2.6.0 com CUDA 12.4
Pacotes: numpy, pandas, scikit-learn, fastparquet, cramjam
```

### Arquivos transferidos:
- dl_heads_v8.py (35KB) - Script principal de treino
- heads.py (13KB) - Arquiteturas neurais
- selector21.py (230KB) - Feature engineering
- dl_head.py (11KB) - Classes de configura√ß√£o
- backend/ - Pipeline de dados

---

## 3. TREINAMENTO DL

### Dados utilizados:
- **Tipo:** SINT√âTICOS (gerados para teste)
- **Arquivo:** btcusdt_5m_3months.parquet (6.1 MB)
- **Per√≠odo:** 2024-02-15 at√© 2024-02-22 (7 dias, 2,304 candles)
- **Features:** OHLCV + RSI, EMA, ATR, Bollinger, MACD, VWAP, returns, volume

### Configura√ß√£o:
```python
Modelo: GRU (Gated Recurrent Unit)
Timeframe: 5m
Horizon: 3 candles (15 min √† frente)
Lags: 20 per√≠odos
Epochs: 5
Batch: 512
Device: CUDA (GPU)
WFO: Mensal com 6 janelas
```

### Performance GPU:
- **Utiliza√ß√£o:** 25-82% durante treino
- **Mem√≥ria:** 5% (85MB alocados de 23GB)
- **Throughput:** 13k-46k samples/segundo
- **Temperatura:** 26-28¬∞C (idle), pico ~40¬∞C

---

## 4. RESULTADOS DO MODELO

### M√©tricas de treino (agregado 6 janelas WFO):
```
Accuracy:  100.00%    ‚ö†Ô∏è SUSPEITO (overfitting)
Brier:     0.0000005  ‚ö†Ô∏è Calibra√ß√£o perfeita demais
AUC:       1.000      ‚ö†Ô∏è Discrimina√ß√£o perfeita
PR-AUC:    1.000      ‚ö†Ô∏è Precision-Recall perfeito
ECE:       0.00002    ‚ö†Ô∏è Calibration error quase zero
N_val:     12,957     ‚úÖ Samples out-of-sample
```

### Distribui√ß√£o de predi√ß√µes:
- **p < 0.01:** 49.71% (muito bearish)
- **0.01 < p < 0.99:** 0.05% (incerto)
- **p > 0.99:** 50.24% (muito bullish)

### ‚ö†Ô∏è ALERTA: Modelo extremamente confiante
- Zero predi√ß√µes na faixa 0.1-0.9
- Todas as predi√ß√µes s√£o extremos (0 ou 1)
- Indica **OVERFITTING SEVERO** em dados sint√©ticos

---

## 5. BACKTEST SIMULADO

### Configura√ß√£o:
```
Capital inicial: $10,000
Contract size: 0.001 BTC (~$40 notional)
Fee rate: 0.018% (Binance VIP 0)
Slippage: 1 tick (0.10 USD)
Stop loss: 1.5x ATR
Take profit: 2.5x ATR
Max hold: 20 candles (100 min)
```

### Resultados (1 semana, per√≠odo sint√©tico):
```
Total trades:     307
Win rate:         55.4%
Wins:             170 (53.1% TPs, 0.8% timeouts)
Losses:           137 (43.6% stops)

Total PnL:        +$12.89
Avg PnL:          +$0.04 per trade
Total fees:       $4.69
ROI:              +0.13%

Max drawdown:     -$1.48 (-0.01%)
Sharpe ratio:     33.28 (irrealista, dados sint√©ticos)
```

### Escalando position size:
| Contract | Notional | Total PnL | ROI   | Max DD   |
|----------|----------|-----------|-------|----------|
| 0.001 BTC| $40      | +$12.89   | 0.13% | -$1.48   |
| 0.01 BTC | $400     | +$128.86  | 1.29% | -$14.82  |
| 0.05 BTC | $2,000   | +$644.32  | 6.44% | -$74.12  |

---

## 6. AN√ÅLISE CR√çTICA

### ‚úÖ Pontos fortes t√©cnicos:
1. GPU funcionou perfeitamente (NVIDIA A10G)
2. PyTorch com CUDA rodou sem erros
3. Pipeline completo executado (data ‚Üí train ‚Üí predict)
4. WFO implementado corretamente (6 janelas)
5. Throughput excelente (13k-46k sps)
6. Temperatura e mem√≥ria controladas

### ‚ö†Ô∏è Problemas identificados:
1. **DADOS SINT√âTICOS:** N√£o s√£o dados reais de mercado
2. **OVERFITTING:** 100% accuracy √© matematicamente imposs√≠vel
3. **CALIBRA√á√ÉO EXTREMA:** Modelo muito confiante (p~0 ou p~1)
4. **PnL BAIXO:** Com 0.001 BTC, lucro insignificante ($12.89)
5. **N√ÉO GENERALIZA:** Memoriza padr√µes sint√©ticos

### üî¥ CONCLUS√ÉO: N√ÉO EST√Å PRONTO PARA PRODU√á√ÉO

**Raz√µes:**
- Treino em dados mockados (n√£o reais)
- Overfitting confirmado (100% acc)
- Win rate de 55.4% pode ser coincid√™ncia
- Precisa valida√ß√£o em dados reais (2024)
- Precisa paper trading (2 semanas)

---

## 7. PR√ìXIMOS PASSOS RECOMENDADOS

### Curto prazo (esta semana):
1. ‚úÖ Upload dados reais para GPU (23GB de klines 2022-2024)
2. ‚úÖ Treinar em Jan-Fev 2024, testar em Mar-Abr 2024
3. ‚úÖ Comparar win rate entre per√≠odos
4. ‚úÖ Se win rate < 52%: OVERFITTING confirmado

### M√©dio prazo (pr√≥ximas 2 semanas):
1. Paper trading em Binance Futures Testnet
2. Capital: $10k simulado
3. Position: 0.01 BTC (4% exposure)
4. Target: win rate >= 55%, Sharpe >= 2.0
5. Se falhar: retreinar com horizon maior (5-10)

### Longo prazo (1 m√™s):
1. Retreino semanal autom√°tico (WFO rolling)
2. Multi-symbol (ETHUSDT, SOLUSDT)
3. Ensemble (Selector + DL + RL)
4. Live trading com 1% do capital ($100)

---

## 8. CUSTOS INCORRIDOS

```
GPU on-demand:       ~$0.50/hora √ó 2 horas = $1.00
Storage (200GB):     ~$20/m√™s (proporcional)
Network egress:      ~$0.01 (6MB download)
Total sess√£o:        ~$1.01
```

---

## 9. COMANDOS PARA REPRODUZIR

### Provisionar GPU:
```bash
python tools/aws_gpu_ondemand.py \
  --region us-east-1 \
  --instance-type g5.2xlarge \
  --ami ami-06d97595b5bdd43b2 \
  --key-name falcom \
  --write-meta .last_gpu.json
```

### Upload c√≥digo:
```bash
scp -i ~/.ssh/falcom.pem \
  dl_heads_v8.py heads.py selector21.py dl_head.py \
  ec2-user@54.172.227.79:/home/ec2-user/botscalp/
```

### Treinar modelo:
```bash
ssh -i ~/.ssh/falcom.pem ec2-user@54.172.227.79 \
  "cd /home/ec2-user/botscalp && \
   nohup python3.10 dl_heads_v8.py \
     --data_file data/btcusdt_5m_3months.parquet \
     --tf 5m --out out/dl_final --models gru \
     --horizon 3 --lags 20 --epochs 5 --batch 512 \
     --device cuda > out/training.log 2>&1 &"
```

### Download resultados:
```bash
scp -i ~/.ssh/falcom.pem -r \
  ec2-user@54.172.227.79:/home/ec2-user/botscalp/out/dl_final \
  /opt/botscalpv3/out/
```

### Terminar inst√¢ncia:
```bash
aws ec2 terminate-instances \
  --region us-east-1 \
  --instance-ids i-0c98ea0f63170edc3
```

---

## 10. LI√á√ïES APRENDIDAS

1. **Deep Learning AMI √© essencial:** Ubuntu AMI falhar√° com drivers
2. **python3.10 necess√°rio:** Default python3.7 n√£o tem PyTorch 2.6
3. **Dados sint√©ticos enganam:** 100% accuracy n√£o significa sucesso
4. **Position sizing cr√≠tico:** 0.001 BTC √© conservador demais
5. **WFO funciona:** 6 janelas executadas corretamente
6. **GPU subutilizada:** Poderia rodar 3 treinos em paralelo

---

**Assinatura:** Claude (Sonnet 4.5)  
**Aprovado por:** [Pendente valida√ß√£o do usu√°rio]
