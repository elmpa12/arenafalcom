#!/usr/bin/env python3
"""
EVOLU√á√ÉO EXPONENCIAL DE ESTRAT√âGIAS - BotScalp V3

As IAs analisam resultados, aprendem padr√µes e GERAM automaticamente
a pr√≥xima gera√ß√£o de testes MELHORADOS.

Uso:
    python3 evolve_strategy.py --generation 1
"""

import os
import json
import glob
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from anthropic import Anthropic

load_dotenv()


def load_all_results(test_dirs):
    """Carrega TODOS os resultados de todos os testes."""
    all_results = {}

    for test_dir in test_dirs:
        test_name = os.path.basename(test_dir)

        # Ler CSVs
        csvs = {}
        for csv_file in glob.glob(f"{test_dir}/*.csv"):
            csv_name = os.path.basename(csv_file)
            try:
                df = pd.read_csv(csv_file)
                csvs[csv_name] = {
                    "rows": len(df),
                    "columns": list(df.columns),
                    "data": df.to_dict('records') if len(df) > 0 else []
                }
            except Exception as e:
                csvs[csv_name] = {"error": str(e)}

        # Ler JSONs
        jsons = {}
        for json_file in glob.glob(f"{test_dir}/*.json"):
            json_name = os.path.basename(json_file)
            try:
                with open(json_file) as f:
                    jsons[json_name] = json.load(f)
            except Exception as e:
                jsons[json_name] = {"error": str(e)}

        all_results[test_name] = {
            "csvs": csvs,
            "jsons": jsons
        }

    return all_results


def analyze_and_evolve(results, generation):
    """Claude + GPT analisam e prop√µem pr√≥xima gera√ß√£o."""

    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

    # Preparar sum√°rio dos resultados
    summary = {}
    for test_name, data in results.items():
        lb = data["csvs"].get("leaderboard_base.csv", {})
        if "data" in lb and lb["data"]:
            best = lb["data"][0] if len(lb["data"]) > 0 else {}
            summary[test_name] = {
                "num_strategies": lb.get("rows", 0),
                "best_method": best.get("method", "N/A"),
                "best_sharpe": best.get("sharpe", "N/A"),
                "best_hit": best.get("hit", "N/A"),
                "best_pnl": best.get("total_pnl", "N/A"),
                "best_trades": best.get("n_trades", "N/A")
            }

    results_str = json.dumps(summary, indent=2, default=str)[:6000]

    print("\n" + "="*80)
    print(f"üß¨ GERA√á√ÉO {generation} - AN√ÅLISE E EVOLU√á√ÉO")
    print("="*80)
    print(f"\nTestes analisados: {len(results)}")
    print()

    # FASE 1: An√°lise de Padr√µes (Claude)
    print("üîµ Claude identificando padr√µes...")

    claude_prompt = f"""Voc√™ √© um especialista em trading quantitativo.

GERA√á√ÉO {generation} - AN√ÅLISE DE RESULTADOS

RESULTADOS DOS TESTES:
{results_str}

TAREFA: Identifique PADR√ïES nos resultados.

1. **O QUE FUNCIONOU?**
   - Quais m√©todos tiveram melhor performance?
   - Quais timeframes?
   - Quais per√≠odos?
   - Por qu√™ voc√™ acha que funcionaram?

2. **O QUE N√ÉO FUNCIONOU?**
   - Quais m√©todos perderam dinheiro?
   - Por qu√™ falharam?
   - Sharpe negativo indica qu√™?

3. **HIP√ìTESES**:
   - Overfitting?
   - Per√≠odos inadequados?
   - M√©todos inadequados para o mercado?
   - Falta de stops adequados?

4. **APRENDIZADOS CHAVE** (3-5 pontos):
   - O que aprendemos desta gera√ß√£o?

Seja ESPEC√çFICO e BASE-SE NOS DADOS."""

    try:
        claude_resp = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3000,
            messages=[{"role": "user", "content": claude_prompt}]
        )
        claude_analysis = claude_resp.content[0].text
        print(f"‚úì Claude completou ({len(claude_analysis)} chars)")
    except Exception as e:
        print(f"‚úó Claude falhou: {e}")
        # Fallback para modelo antigo
        try:
            claude_resp = anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=3000,
                messages=[{"role": "user", "content": claude_prompt}]
            )
            claude_analysis = claude_resp.content[0].text
            print(f"‚úì Claude (haiku) completou ({len(claude_analysis)} chars)")
        except Exception as e2:
            claude_analysis = f"[ERRO: {e2}]"

    # FASE 2: Propostas de Melhoria (GPT)
    print("\nüü¢ GPT propondo melhorias...")

    gpt_prompt = f"""GERA√á√ÉO {generation} - PROPOSTAS DE MELHORIA

AN√ÅLISE DO CLAUDE:
{claude_analysis[:2000]}

RESULTADOS:
{results_str[:2000]}

TAREFA: Propor MELHORIAS CONCRETAS para Gera√ß√£o {generation+1}.

1. **AJUSTES DE PAR√ÇMETROS**:
   - Quais par√¢metros devemos testar?
   - Valores espec√≠ficos?
   - Por qu√™ esses valores?

2. **NOVOS M√âTODOS/COMBOS**:
   - Quais m√©todos testar?
   - Combos promissores?

3. **PER√çODOS ALTERNATIVOS**:
   - Testar outros per√≠odos?
   - Por qu√™ esses per√≠odos?

4. **FILTROS/STOPS**:
   - Como melhorar risk management?
   - Stops din√¢micos?

5. **TOP 5 EXPERIMENTOS** para Gera√ß√£o {generation+1}:
   - Liste 5 testes concretos
   - Para cada um: objetivo, config, hip√≥tese

Seja ESPEC√çFICO e ACION√ÅVEL."""

    try:
        gpt_resp = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": gpt_prompt}],
            max_tokens=3000
        )
        gpt_proposals = gpt_resp.choices[0].message.content
        print(f"‚úì GPT completou ({len(gpt_proposals)} chars)")
    except Exception as e:
        print(f"‚úó GPT falhou: {e}")
        gpt_proposals = f"[ERRO: {e}]"

    # FASE 3: Consenso e Gera√ß√£o de Testes
    print("\nüéØ Gerando pr√≥xima gera√ß√£o de testes...")

    consensus_prompt = f"""GERA√á√ÉO {generation+1} - CRIAR NOVOS TESTES

AN√ÅLISE CLAUDE:
{claude_analysis[:1500]}

PROPOSTAS GPT:
{gpt_proposals[:1500]}

TAREFA: Gerar configura√ß√£o Python para Gera√ß√£o {generation+1}.

Crie 5-10 NOVOS testes baseados nos aprendizados.

Formato:
```python
TESTS_GEN{generation+1} = [
    {{
        "name": "gen{generation+1}_test1_nome",
        "desc": "Descri√ß√£o clara do objetivo",
        "hypothesis": "Por que achamos que vai funcionar",
        "args": [
            "--umcsv_root", "./data_monthly",
            "--symbol", "BTCUSDT",
            "--start", "YYYY-MM-DD",
            "--end", "YYYY-MM-DD",
            # ... TODOS os argumentos necess√°rios
            "--out_root", "./resultados/gen{generation+1}/test1"
        ]
    }},
    # ... mais testes
]
```

IMPORTANTE:
- Use argumentos REAIS do selector21.py
- Varie per√≠odos, m√©todos, timeframes baseado no aprendizado
- Teste hip√≥teses espec√≠ficas
- Cada teste deve ter OBJETIVO claro"""

    try:
        final_resp = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": consensus_prompt}],
            max_tokens=4000
        )
        next_gen_code = final_resp.choices[0].message.content
        print(f"‚úì Gera√ß√£o {generation+1} criada ({len(next_gen_code)} chars)")
    except Exception as e:
        print(f"‚úó Gera√ß√£o falhou: {e}")
        next_gen_code = f"[ERRO: {e}]"

    # Salvar tudo
    output = {
        "generation": generation,
        "num_tests_analyzed": len(results),
        "claude_analysis": claude_analysis,
        "gpt_proposals": gpt_proposals,
        "next_generation_code": next_gen_code,
        "summary": summary
    }

    gen_dir = f"./evolution/gen{generation}"
    os.makedirs(gen_dir, exist_ok=True)

    with open(f"{gen_dir}/analysis.json", "w") as f:
        json.dump(output, f, indent=2, default=str)

    with open(f"{gen_dir}/next_generation.py", "w") as f:
        f.write(f"# GERA√á√ÉO {generation+1} - Auto-gerada pelas IAs\n\n")
        f.write(next_gen_code)

    with open(f"{gen_dir}/LEARNING.md", "w") as f:
        f.write(f"# APRENDIZADOS - GERA√á√ÉO {generation}\n\n")
        f.write("## An√°lise Claude\n\n")
        f.write(claude_analysis)
        f.write("\n\n## Propostas GPT\n\n")
        f.write(gpt_proposals)
        f.write("\n\n## Pr√≥xima Gera√ß√£o\n\n")
        f.write(next_gen_code)

    print(f"\n{'='*80}")
    print("üíæ EVOLU√á√ÉO SALVA")
    print("="*80)
    print(f"\n  ‚Ä¢ evolution/gen{generation}/analysis.json")
    print(f"  ‚Ä¢ evolution/gen{generation}/next_generation.py")
    print(f"  ‚Ä¢ evolution/gen{generation}/LEARNING.md")
    print()

    return output


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--generation", type=int, default=1, help="N√∫mero da gera√ß√£o")
    parser.add_argument("--test_dir", type=str, default="./resultados/test*",
                        help="Pattern dos diret√≥rios de teste")
    args = parser.parse_args()

    print("="*80)
    print("üß¨ EVOLU√á√ÉO EXPONENCIAL DE ESTRAT√âGIAS")
    print("="*80)
    print(f"\nGera√ß√£o atual: {args.generation}")
    print()

    # Carregar resultados
    test_dirs = glob.glob(args.test_dir)
    if not test_dirs:
        print(f"‚ö†Ô∏è  Nenhum diret√≥rio encontrado: {args.test_dir}")
        return

    print(f"üìÇ Carregando resultados de {len(test_dirs)} testes...")
    results = load_all_results(test_dirs)
    print(f"‚úì {len(results)} testes carregados")

    # Analisar e evoluir
    evolution = analyze_and_evolve(results, args.generation)

    print("\n" + "="*80)
    print("‚úÖ EVOLU√á√ÉO COMPLETA!")
    print("="*80)
    print(f"\nüìä Pr√≥ximo passo:")
    print(f"   1. Revisar: cat evolution/gen{args.generation}/LEARNING.md")
    print(f"   2. Executar: python3 evolution/gen{args.generation}/next_generation.py")
    print()


if __name__ == "__main__":
    main()
